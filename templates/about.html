{% extends 'index.html' %}

{% block body %}
<br>

<h3>Welcome to The Project "Extract Meaningful Data from Visiting Card using NER Model"</h3>

    <p>These days there is a huge demand for extraction of the meaningful data
        available in paper documents format into a computer storage disk and then later
        reusing this information. One simple way to store information from these paper
        documents in the computer system is to first scan the documents and then store
        them as images. In this project, we tried to extract entities like Name,
        Organization, Designation, Phone Number, Email Address and Website from
        the scanned Visiting Card. In this project, we used different technologies like
        Computer Vision, Natural Language Processing(NLP) and Deep Learning.
        Using Computer Vision, we scanned the document, identified the location of
        the text and finally extracted text from the image using Pytesseract. Then the
        necessary cleaning was done and the text was prepared for tagging. After that,
        the text was manually labeled using BIO tagging. In the BIO technique B, I and
        O stand for beginning, inside, outside. After some normalized training data is
        prepared and converted into spacy format. With the preprocess data the
        Named Entity model was trained. This Named Entity Recognition Model used
        the word embedding strategy using subword features. We can predict the
        entities using the NER model. For extracted text from the image, we detailed
        study the Tesseract Open Source OCR Engine. ‘OpenCV Computer Vision
        with Python’ Book helped us for a detailed understanding of the Python
        Library OpenCV.</p>
        
        
    <p>
        In Computer Vision module, we will scan the document, identify the location of text and finally extract text from the image. 
        Then in Natural language processing, 
        we will extract the entitles from the text and do necessary text cleaning and parse the entities form the text.
    </p> 
        
    <p><strong>Python Libraries used in Computer Vision Module.</strong></p> 
    <ul>
        <li>OpenCV</li>
        <li>Numpy</li>
        <li>Pytesseract</li>
    </ul>
    <p><strong>Python Libraries used in Natural Language Processing</strong></p>
    <ul>
        <li>SpaCy</li>
        <li>Pandas</li>
        <li>Regular Expression</li>
        <li>String</li>
    </ul>
    <p>
        As are combining two major technologies to develop the project, 
        for the sake of easy to understand we divide the course into several stage of development.
    </p>
        
    <p>
        <strong>Stage -1: We will setup the project by doing the necessary installations and requirements.</strong>
        <ul>
            <li>Install Python</li>
            <li>Install Dependencies</li>
        </ul>

    </p>
    <p>
        <strong>Stage -2: We will do data preparation. That is we will extract text from images using Pytesseract and also do necessary cleaning.</strong>
        <ul>
            <li>Gather Images</li>
            <li>Overview on Pytesseract</li>
            <li>Extract Text from all Image</li>
            <li>Clean and Prepare text</li>
        </ul>
    </p>
    <p>
       <strong>Stage -3: We will see how to label NER data using BIO tagging.</strong> 
        <ul>
            <li>Manually Labeling with BIO technique
                <ul>
                    <li>B - Beginning</li>
                    <li>I  -  Inside</li>
                    <li>O - Outside</li>
                </ul>
            </li>
        </ul>
    </p>
        
    <p>
        <strong>Stage -4: We will further clean the text and preprocess the data for to train machine learning.</strong>
        <ul>
            <li>Prepare Training Data for Spacy</li>
            <li>Convert data into spacy format</li>
        </ul>
    </p>

    <p>
        <strong>Stage -5: With the preprocess data we will train the Named Entity model.</strong>
        <ul>
            <li>Configuring NER Model</li>
            <li>Train the model</li>
        </ul>
    </p>
        
    <p>
        <strong>Stage -6: We will predict the entitles using NER and model and create data pipeline for parsing text.</strong>
        <ul>
            <li>Load Model</li>
            <li>Render and Serve with Displacy</li>
            <li>Draw Bounding Box on Image</li>
            <li>Parse Entitles from Text</li>
        </ul>
    </p>
        
    <h4>Finally, we will put all together and create document scanner web application.</h4>

{% endblock  %}
